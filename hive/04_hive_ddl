------------------------------------------------------------
CHAPTER 4 - HIVE TABLES DDL
------------------------------------------------------------

- Schema-On-Read

    - The versatility and power of Hadoop lies in its ability to store and process any kind of 
        unstructured, semi-structured, or structured data.  Hive allows users to create a metadata layer
        on top of this data and access it using a SQL interface.


    - Since the underlying data in HDFS can be of any format, Hive lets you provide additional 
        information in the metadata to explain exactly the nature in which the data stored is formatted.
        Most of the Hive CREATE statements provide additional information such as how the underlying
        data is structured, how the records are defined, and how fields are separated.



- Hive Data Model

    - Hive's data model is quite similar to various relational databases.  It consists of a schema of
        tables, columns, rows, and partitions.  These objects are logical units that are defined in the
        metadata layer called the Hive Metastore.  In addition to the common data segments, Hive 
        introduces an additional structure called 'buckets'.


    - The Hive Metastore consists of namespaces, object definitions, and the details of the underlying
        data.  As of today, a Hive Metastore is created in an RDBMS, as it is quite critical to have
        fast access to this information.  



- Schemas

    - A Hive schema (or database) is essentially a namespace that holds metadata information for a set
        of tables.  'Schema' and 'database' are synonyms in terms of Hive.  At the filesystem level, it
        is a directory under which all internal tables that belong to the namespace are stored.  Hive
        also has a concept of external tables in which the files might exist in other locations in 
        HDFS.


    - All the data managed by Hive gets stored under a top-level directory defined using the 
        'hive.metastore.warehouse.dir' parameter in the 'hive-site.xml' file.  When you install Hive for
        the first time, it creates a default database called 'default', which itself does not have its
        own directory.  All the internal tables created in the default database are stored under the
        top-level directory in their respective subdirectories.


    - Prior to the addition of the concept of databases in Hive, all user objects were created in a 
        single namespace.  Creating multiple schemas allows users to create objects in different
        namespaces.  So, it allows for logical grouping of various objects.  You can also assign different
        properties (ie different owners, permissions, and warehouse directories) for different databases.



- Creating Databases

    - You can create a database in Hive using the CREATE DATABASE command.  

        # Create the shopping database
        hive> CREATE DATABASE shopping;

      This creates a new namespace called 'Shopping' in the Hive metastore.  In this example, since we
        have not specified a location for this database on HDFS, it will create a directory called 
        'Shopping.db' under the default top-level directory defined in 'hive.metastore.warehouse.dir'.


    - The complete syntax of the CREATE DATABASE command is:

        CREATE (DATABASE | SCHEMA) [ IF NOT EXISTS ] database_name
        [ COMMENT database_comment ]
        [ LOCATION hdfs_path ]
        [ WITH DBPROPERTIES (property_name = property_value,...) ] ;

      Here is an example:

        CREATE DATABASE  IF NOT EXISTS  shopping
        COMMENT 'stores all shopping basket data'
        LOCATION '/user/retail/hive/SHOPPING.db'
        WITH DBPROPERTIES ('purpose' = 'testing') ;


    - The WITH DBPROPERTIES clause let's you assign any custom properties to a database.  These properties
        can be viewed with the DESCRIBE DATABASE EXTENDED command.  



- Altering Databases

    - Once you have created a database, you can modify its metadata properties (DBPROPERTIES) or OWNER
        using the ALTER DATABASE command.

        # Change DBPROPERTIES
        ALTER DATABASE shopping
        SET DBPROPERTIES ('department' = 'SALES');



- Dropping Databases

    - A Hive database can be dropped using the DROP DATABASE command.

        DROP DATABASE database_name [RESTRICT | CASCADE];

      For example:

        DROP DATABASE shopping CASCADE;


    - The CASCADE in this command is optional and allows you to drop a database with existing tables.
        The above command will drop all internal and external tables that belong to the shopping
        database.

      The default behavior of the DROP DATABASE command is RESTRICT, which means if there are any
        tables in the database, the command will fail.



- Listing Databases

    - You can view the list of all databases in the metastore using:

        SHOW DATABASES [LIKE 'identifier_with_wildcards'];

      For example:

        SHOW DATABASES LIKE 'S*';



- Primitive Data Types

    - Each column value in Hive has a data type, which has constraints and a valid range of values.  The
        behavior of these data types is similar to the underlying data types in Java in which they are
        implemented.  The primitive types are:

        1. Numeric types = integers and floating points

        2. Date/time types

        3. Character data types

        4. Booleans

        5. Binary


    - Since Hadoop often contains various types of data, it's often better to use a less restrictive
        data type for a column.  For instance, a 'STRING' column provides much more flexibility than a
        'VARCHAR(25)'.  



- Complex Data Types

    - Apart from the primitive types, Hive also contains a few types that are not usually found in 
        relational databases.  These consist of collection types, and are internally implemented using
        native serializers and deserializers.  The complex data types are:

        1. Arrays

        2. Maps

        3. Structs

        4. Unions


    - A Hive array is an ordered collection of elements with a similar type.  

        # Creates an array named ITEMS
        ITEMS ARRAY<"Bread", 'Butter', "Organic Eggs">

        # Access elements (0-index)
        ITEMS[0]
        ITEMS[2]


    - A Hive map is an unordered collection of key/value pairs.  The key must be one of the primitive
        types.  The value can be any Hive type, including a complex type.

        # Create and populate a map
        Basket MAP<'string', 'int'>
        Basket MAP<"Eggs", '12'>

        # Access elements
        Basket("Eggs")       # Returns 12


    - A Hive struct contains various fields that can be of any data type.

        # Create a struct
        address STRUCT<houseno:STRING, 
                       street:STRING, 
                       city:STRING, 
                       zipcode:INT, 
                       state:STRING, 
                       country:STRING>

        address <"17","MAIN ST", "SEATTLE", 98104, "WA","USA">


    - A Hive union provides a way to store elements of different data types in different rows of the
        same field.  This is useful when the underlying data of a field is not homogenous.

        # Customer's contact details may consist of 1 or more phone numbers and 1 or more emails
        contact UNIONTYPE <int, array<int>, string, array<string>>



- Tables

    - A Hive data model contains a logical row/column view of data referred to as a 'table'.  However,
        in Hive, the data exists independently of the data.  The data in a Hive table is stored in an
        HDFS directory, and the definition of the table is stored in a relational database store
        called HCatalog.


    - Key differences in Hive from relational databases include:

        1. The data in a Hive table is loosely coupled from its definition.  If you drop a table in Hive,
             the table definition will be dropped independently of the underlying data.

        2. A single data set in Hive can have multiple table definitions.

        3. The underlying data in a Hive table can be stored in a variety of formats.



- Creating Tables

    - Tables are created in Hive using the CREATE TABLE statement.  The configuration specified during 
        the creation of a table defines how Hive will interpret the underlying data.  Hive has many 
        built-in data format interpreters, or 'SerDes' as they are called in Hive's language.  Hive
        also allows you to create your own serializer-deserializers and just plug them into a CREATE
        TABLE statement to enable Hive to understand the format of your data.


    - Here is a CREATE TABLE example, which is created in the default database:

        CREATE EXTERNAL TABLE customers (
        fname           STRING,
        lname           STRING,
        address         STRUCT <HOUSENO:STRING, STREET:STRING, CITY:STRING, ZIPCODE:INT, 
                                STATE:STRING, COUNTRY:STRING>,
        active          BOOLEAN,
        created         DATE
        LOCATION '/user/demo/customers');


    - Here is an example of a table created in an existing database:

        CREATE EXTERNAL TABLE retail.customers (
        fname           STRING,
        lname           STRING,
        address         STRUCT <HOUSENO:STRING, STREET:STRING, CITY:STRING, ZIPCODE:INT,
                        STATE:STRING, COUNTRY:STRING>,
        active          BOOLEAN,
        created         DATE)
        COMMENT "customer master record table"
        LOCATION '/user/demo/customers/';



- Listing Tables

    - You can list all the existing tables using the SHOW TABLES command.

        # List all the tables in the RETAIL database
        hive> SHOW TABLES IN retail;


    - If there are many tables, you can search with wildcards.



- Internal and External Tables

    - External tables are created using the EXTERNAL keywords in the CREATE TABLE statement.  This is
        the recommended table type for all production deployments.  This is because in most cases the
        underlying data will be used for multiple use cases.  Even if it is not, the data should not
        be dropped when the table definition is dropped.  

      In the case of external tables, Hive does not drop the data from the filesystem as it does not
        have control over it.  External tables are used in the following cases:

        1. When you want to drop table definitions without worrying about deleting the underlying data

        2. When the data is stored in filesystems other than HDFS (ie S3)

        3. You want to use a custom location to store the table data

        4. You are not creating a table based on another table (CREATE TABLE AS SELECT)

        5. Data will be accessed by multiple processing engines (ie you want to read the table in 
             Hive and also use it in a Spark program)

        6. You want to create multiple tables' definitions over the same data set.  If you have multiple
             table definitions, dropping one of them should not delete the underlying data.


    - An internal table is a table whose data is managed by Hive.  This means when an internal table
        is deleted, the underlying data is deleted also.  These tables are not used very often in most
        Hadoop environments.  Internal tables are used in the following tables:

        1. The data stored is temporary

        2. When the only way the data is accessed is through Hive and you want Hive to completely
             manage the lifecycle of the table and the data.



- Internal and External Tables Example

    # Load a file to hdfs and verify it
    $ hdfs dfs -put /tmp/states.txt /user/demo/states/
    $ hdfs dfs -ls /user/demo/states/


    # Create an internal table to access the data in the 'states.txt' file
    hive> CREATE TABLE states_internal (state string) LOCATION '/user/demo/states';


    # Look at the table definition
    hive> DESCRIBE FORMATTED states_internal;


    # Query data from the internal table
    hive> SELECT * FROM states_internal;


    # Create an external table on the same data
    hive> CREATE EXTERNAL TABLE states_external (state string) LOCATION '/user/demo/states';


    # Look at the table definition
    hive> DESCRIBE FORMATTED states_external;


    # Query from the external table
    hive> SELECT * FROM states_external;



- Table Properties

    - You can also specify some tabel-level properties while creating a table or by altering a table
        using the TBLPROPTERTIES clause.  Hive has some predefined essential properties for tables, 
        and you can also define custom properties using a key-value format to store some table-level
        metadata or additional information about the table.


    - Some of the important table-level properties in Hive are:

        - last_modified_user (managed by Hive)
        - last_modified_time (managed by Hive)
        - immutable
        - orc.compress
        - skip.header.line.count


    - The 'skip.header.line.count' property is often used.

        $ hadoop fs -cat /user/demo/states3/states3.txt

        STATE_NAME
        ----------
        california
        ohio
        north dakota
        new york
        colorado
        new jersey


        # Skip the first 2 lines when processing data
        hive> CREATE EXTERNAL TABLE states3 (states string) LOCATION '/user/demo/states3' 
                 TBLPROPERTIES("skip.header.line.count"="2");



- Partitioning and Bucketing

    - 
-----------------------------------------------------------------------
|  CHAPTER 3 - HDFS                                                   |
-----------------------------------------------------------------------

- Design of HDFS

    - HDFS is designed for 

        - Storing very large files
        - Streaming data access (write-once, read many times)
        - Commodity hardware


    - HDFS is not well suited for

        - Low-latency data access
        - Lots of small files (NameNode holds all metadata in memory)
        - Multiple writers or arbitrary file modifications



- HDFS Blocks

    - A disk has a block size, the minimum amount it can read or write at a time (usually 
        512 bytes).  Filesystems build on this by dealing with data in blocks.  In a typical
        filesystem, blocks are a few KB (4 KB for ext4).


    - HDFS uses 128 MB blocks by default.  Unlike with regular filesystems, files are not
        required to encompass entire blocks (a 1 MB file in a 128 MB block only uses 1 MB).
        HDFS blocks are large to minimize the cost of seeks.


    - Using a block abstraction in a distributed filesystem has several benefits:

        1. A file can be larger than any single disk in the network.

        2. It makes keeping track of metadata simpler, since all blocks are the same size.

        3. It makes replication simpler.


    - Like it's disk filesystem cousin, HDFS's 'fsck' command understands blocks.

        # List the blocks that make up each file in the filesystem
        $ hdfs fsck / -files -blocks



- NameNodes and DataNodes

    - An HDFS cluster has 2 types of nodes operating in a master-worker pattern:

        1. A NameNode

             - Manages the filesystem namespace
             - Maintains the tree and metadata for all files and directories
             - Stored persistenly on the local disk in both the namespace image and edit log
             - Knows which DataNodes the blocks for each file are located on
             - Does not store DataNodes information persistently, constructs this at startup


        2. DataNodes

             - Workhorses of the filesystem
             - Store and retrieve blocks
             - Report back to the NameNode periodically with the list of blocks they are storing 


    - A client accesses the filesystem on behalf of the user by communicating with the NameNode
        and DataNodes.  The client presents an interface similar to POSIX.


    - The NameNode must be resistant to failure, since there would be no way to reconstruct
        the files on the filesystem without it.  There are 2 methods for this:

        1. Back up the files that make up the persistent state of the filesystem metadata.
             Hadoop can be configured so that the NameNode writes its persistent state to
             multiple filesystems.  These writes are synchronous and atomic.  Usually, it
             is written both locally and to an NFS mount.

        2. Run a secondary NameNode.  It does not actually act as a NameNode.  Its main role is
             to periodically merge the namespace image with the edit log to prevent the edit 
             log from becoming too large.  It runs on a separate machine, as it required lots
             of CPU and as much memory as the main NameNode.

           It keeps a copy of the merged namespace image, which can be used if the main NameNode
             fails.  However, it lags the primary, so data loss is almost certain in a failure.



- Block Caching

    - Normally a datanode reads blocks from disk, but for frequently accessed files the blocks may 
        be explicitly cached in the DataNode’s memory, in an off-heap 'block cache'.


    - By default, a block is cached in only one DataNode’s memory, although the number is 
        configurable on a per-file basis.  Job schedulers (ie MapReduce, Spark) can take advantage 
        of cached blocks by running tasks on the DataNode where a block is cached.  A small lookup table 
        used in a join is a good candidate for caching, for example.  


    - Users or applications instruct the NameNode which files to cache (and for how long) by adding a 
        cache directive to a cache pool. Cache pools are an administrative grouping for managing cache 
        permissions and resource usage.



- HDFS Federation

    - HDFS Federation allows a cluster to scale by adding NameNodes, each of which manages 
        a portion of the filesystem namespace.  Under federation, each NameNode manages a
        namespace volume and block pool.


    - Namespace volumes are independent of each other, which means NameNodes do not communicate
        with each other.



- HDFS High Availability

    - Replicating NameNode metadata on multiple filesystems and using a secondary NameNode
        protects against data loss, but does not provide high availability of the filesystem.
        
      The NameNode is still a single point of failure, and if it fails the entire Hadoop
        cluster is out of service until a new NameNode is online.


    - To recover from a failed NameNode, an admin starts a new primary NameNode with one of
        the filesystem metadata replicas.  The new NameNode then needs to:

        1. Load the namespace image into memory

        2. Replay the edit log

        3. Receive enough block reports from DataNodes to leave safe mode

      In large clusters, this may be 30 minutes of more.


    - This is also a problem in routine maintenance, which occurs much more often than node
        failure.


    - Hadoop 2 remedied this by adding HDFS HA.  In this implementation, there is a pair of 
        NameNodes in an active-standby configuration.  

      If the primary fails, the standby takes over without significant interruption.  A few
        architectural changes are required for this:

        1. The NameNodes must use highly available shared storage to share the edit log.

        2. DataNodes must send block reports to both NameNodes, since the block mappings are
             stored in memory.

        3. Clients must be configured to handle NameNode failover.

        4. The Secondary NameNode is removed in favor of the Standby NameNode.


    - There are 2 choices available for the highly available shared storage for the edit log:

        1. An NFS Filer

        2. A Quorum Journal Manager



- Failover and Fencing

    - The transition from the active NameNode to the standby is managed by a 'failover controller'.
        By default, ZooKeeper is used.  It ensures only one NameNode is active at a time.


    - Failover may be initiated manually by an admin or automatically if a failure is detected.
        If a failover is detected, the HA implementation ensures that the previously active 
        NameNode doesn't do any damage.  This is known as 'fencing'.


    - Tactics for fencing range from setting up an SSH command to kill a NameNode process to 
        using a specialized PSU that can be cut off.



- Basic Filesystem Operations

    - In pseudo-distributed mode, we use the following settings:

        # File: /etc/hadoop/core-site.xml
        -----------------------------------------
        fs.defaultFS = hdfs://localhost/
        dfs.replication = 1


    - Getting help:

        $ hadoop fs -help


    - Copying files:

        # Copy a file from the local filesystem to HDFS
        $ hadoop fs -copyFromLocal input/docs/quangle.txt hdfs://localhost/user/tom/quangle.txt

        # Can omit the hdfs://localhost since its in config
        $ hadoop fs -copyFromLocal input/docs/quangle.txt /user/tom/quangle.tx

        # Can also omit HDFS home directory
        $ hadoop fs -copyFromLocal input/docs/quangle.txt quangle.txt


        # Copy file back to local filesystem
        $ hadoop fs -copyToLocal quangle.txt quangle.copy.txt

        # Verify files are the same
        $ md5 input/docs/quangle.txt quangle.copy.txt


    - Creating directories:

        # Create a directory
        $ hadoop fs -mkdir books

        # View directory contents
        $ hadoop fs -ls .



- Hadoop Filesystems

    - Hadoop has an abstract notion of filesystems, of which HDFS is just one implementation.
        The Java abstract class org.apache.hadoop.fs.FileSystem represents the client interface
        to a filesystem in Hadoop, and there are several concrete implementations.


    - Here are the main ones that ship with Hadoop:

        Filesystem   URIscheme    Java implementation            Description
                                  (all under org.apache.hadoop)
        --------------------------------------------------------------------------------------------
        Local        file         fs.LocalFileSystem             A filesystem for a locally connected
                                                                   disk with client-side checksums. Use 
                                                                   RawLocalFileSystem for a localfilesystem 
                                                                   with no checksums.

        HDFS         hdfs         hdfs.DistributedFileSystem    Hadoop’s distributed filesystem. HDFS is
                                                                  designed to work efficiently in conjunction
                                                                  with MapReduce.

        WebHDFS      webhdfs      hdfs.web.WebHdfsFileSystem    A filesystem providing authenticated 
                                                                  read/write access to HDFS over HTTP.

        SecureWebHDFS swebhdfs    hdfs.web.SWebHdfsFileSystem   The HTTPS version of WebHDFS.

        HAR          har          fs.HarFileSystem              A filesystem layered on another filesystem 
                                                                  for archiving files. Hadoop Archives are 
                                                                  used for packing lots offiles in HDFS into 
                                                                  a single archive file to reduce the 
                                                                  namenode’s memory usage. Use the hadoop
                                                                  'archive' command to create HAR files.

        View         viewfs       viewfs.ViewFileSystem         A client-side mount table for other Hadoop
                                                                  filesystems. Commonly used to create mount
                                                                  points for federated NameNodes .

        FTP          ftp          fs.ftp.FTPFileSystem          A filesystem backed by an FTP server.

        S3           s3a          fs.s3a.S3AFileSystem          A filesystem backed by Amazon S3.

        Azure        wasb         fs.azure.NativeAzure          A filesystem backed by Microsoft Azure.
                                    .FileSystem

        Swift        swift        fs.swift.snative              A filesystem backed by OpenStackSwift.
                                    .SwiftNativeFileSystem


    - To list the files in the root directory of the local filesystem:

        $ hadoop fs -ls file:///



- Interfaces

    - Hadoop is written in Java, so most Hadoop filesystem interactions are mediated through
        the Java API.  However, there are several other filesystem interfaces.


    - HTTP

        The WebHDFS protocol exposes a REST API to make it easier for other languages to
          interact with HDFS.  Either web servers are embedded on the NameNodes and DataNodes
          or a proxy server is used in between clients and the nodes.


    - C

        The C 'libhdfs' library works similarly to the Java library.  However, the Java 
          library often gets new features first. 

        
    - NFS

        It is possible to mount HDFS on a local client's filesystem using NFSv3.  Then
          you can use standard Unix utilities to interact with the filesystem.


    - FUSE

        'FileSystem in Userspace' allows systems that are implemented in user space to be
          integrated into Unix filesystems.  Hadoop's FUSE-DFS module allows HDFS to be
          mounted as a standard local filesystem.



- The Java Interface - Reading Data from a Hadoop URL

    - We have to do some work to make Java recognize Hadoops 'hdfs' URL scheme.  This is
        achieved by calling the 'setURLStreamHandlerFactory()' method on a URL with an
        instance of 'URLStreamHandlerFactory'.  This method can only be called once per JVM,
        so it is usually a static method.


    - This program displays output from Hadoop filesystems on standard output, similar to the
        Unix cat command.

        public class URLCat {

            static {
                URL.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory());
            }
        
            public static void main (String args[]) {
                InputStream in = null;
        
                try {
                    in = new URL(args[0]).openStream();
                    IOUtils.copyBytes(in, System.out, 4096, false);
                }
                finally {
                    IOUtils.closeStream(in);
                }
            }
        }


    - To run it:

        $ hadoop URLCat hdfs://localhost/user/tom/quangle.txt



- Reading Data Using the FileSystem API

    - Sometimes, it is impossible to set a 'URLStreamHandlerFactory' in your application,
        for instance if you have set it somewhere else.  In this case, you will need to use
        the 'FileSystem' API to open an input stream for a file.


    - Here is a program that dispalys files from a Hadoop filesystem on standard output by
        using the 'FileSystem' directly:

        public class FileSystemCat {
    
            public static void main(String[]args) throws Exception {
                String uri = args[0];
                Configuration conf = new Configuration();
                FileSystem fs = FileSystem.get(URI.create(uri),conf);
                InputStream in = null;
        
                try {
                    in = fs.open(newPath(uri));
                    IOUtils.copyBytes(in,System.out,4096,false);
                }
                finally {
                    IOUtils.closeStream(in);
                }
            }
        }


    - To run it:

        $ hadoop FileSystemCat hdfs://localhost/user/tom/quangle.txt



- FSDataInputStream

    - The 'open()' method on a 'FileSystem' returns an 'FSDataInputStream' rather than a
        standard 'java.io' class.  It has support for random access, so you can read from
        any part of the stream.

        public class FileSystemDoubleCat {
    
            public static void main(String[]args) throws Exception {
                String uri = args[0];
                Configuration conf = new Configuration();
                FileSystem fs = FileSystem.get(URI.create(uri),conf);
                FSDataInputStreamin=null;
        
                try {
                    in = fs.open(newPath(uri));
                    IOUtils.copyBytes(in,System.out,4096,false);
                    in.seek(0);  // go back to the start of the file
                    IOUtils.copyBytes(in,System.out,4096,false);
                }
                finally {
                    IOUtils.closeStream(in);
                }
            }
        }


    - To run it:

        $ hadoop FileSystemDoubleCat hdfs://localhost/user/tom/quangle.txt



- Writing Data

    - Here, we copy a local file to a Hadoop filesystem:

        public class FileCopyWithProgress {
    
            public static void main(String[]args) throws Exception {
                String localSrc = args[0];
                String dst=args[1];
                InputStream in = new BufferedInputStream(newFileInputStream(localSrc));
                Configuration conf = new Configuration();
                FileSystem fs = FileSystem.get(URI.create(dst),conf);
                OutputStream out = fs.create(newPath(dst), new Progressable() {
                    public void progress() {
                        System.out.print(".");
                    }
                });
        
                IOUtils.copyBytes(in,out,4096,true);
            }
        }



- Querying Data - File metadata and FileStatus

    - The 'FileStatus' class encapsulates filesystem metadata for files and directories, 
        including file length, block size, replication, modification time, ownership, and 
        permission information.


    - An example testing this class is located at 'code/ch03/ShowFileStatusTest.java'.


- Listing Files


- File Patterns


- PathFilter


- Deleting Data


- Data Flow - File Read


- Data Flow - File Write


- Coherency Model


- Consequences for Application Design


- Parallel Copying with distcp


- Keeping an HDFS Cluster Balanced
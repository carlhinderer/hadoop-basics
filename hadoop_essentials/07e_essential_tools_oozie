------------------------------------------------------------
CHAPTER 7E - ESSENTIAL TOOLS - OOZIE
------------------------------------------------------------

- Apache Oozie

    - Oozie is a workflow director system designed to run and manage multiple related Hadoop jobs.
        For instance, complete data input and analysis may require several discrete Hadoop jobs
        to be run as a workflow in which the output of one job serves as the input for a 
        successive job.  Oozie is designed to construct and manage these workflows.


    - Oozie workflow jobs are represented as DAGs of actions.  3 types of Oozie jobs are permitted:

        1. Workflow = a specified sequence of Hadoop jobs with outcome-based decision points and 
             control dependency.  Progress from one action to another cannot happen until the first
             action is complete.

        2. Coordinator = a scheduler workflow job that can run at various time intervals or when
             data become available

        3. Bundle = a higher-level Oozie abstraction that will batch a set of coordinator jobs


    - Oozie is integrated with the rest of the Hadoop stack, supporting several types of Hadoop jobs
        out of the box (ie MapReduce, Streaming MapReduce, Pig, Hive, Sqoop) as well as system-specific
        jobs (ie Java programs and shell scripts).  Oozie also provides a CLI and a web UI for
        managing jobs.



- Oozie Workflow Definitions

    - Oozie workflow definitions are written in hPDL (an XML Process Definition Language).  Such
        workflows contain several types of nodes:

        1. Control Flow Nodes
             - Define the beginning and end of a worflow
             - They include start, end, and optional fail nodes

        2. Action Nodes
             - Where the actual processing tasks are defined
             - When an action node finishes, the remote systems notify Oozie and next node is executed
             - Action nodes can also include HDFS commands

        3. Fork/join Nodes
             - Enable parallel execution of tasks in the workflow
             - The fork node enables 2 or more tasks to run at the same time
             - A join node represents a rendezvous point that must wait until all forked tasks complete

        4. Decision Control Nodes
             - Enable decisions to be made about the previous task
             - Control decisions are based on the results of the previous action (eg file existence)
             - Decision nodes are essentially switch-case statements that use JSP EL
                 (Java Server Pages - Expression Language) that evaluate to either true or false



- Oozie Workflow DAG Example


                                             MapReduce
                                           / streaming \                   
             Start --> MapReduce --> fork                join --> decision 
                                           \           /           |    |  
                                                pig              map    |
                                                               reduce   |
                                                                pipes   |
                                                                   |    |
                                                                   |    |
                                                                   v    v
                                                                    java
                                                                      |
                                                                      v
                                                                 file system
                                                                      |
                                                                      v
                                                                     end



- Download Oozie Examples

    # Extract and rename the example files
    $ tar xvzf /usr/hdp/2.2.4.2-2/oozie/doc/oozie-examples.tar.gz
    $ mv examples oozie-examples


    # Move the example files into HDFS
    $ hdfs dfs -put oozie-examples/ oozie-examples


    The example applications are found under the 'oozie-examples/app' directory, one directory per 
      example. Each directory contains at least 'workflow.xml' and 'job.properties' files. Other 
      files needed for each example are also in its directory. The inputs for all examples are in the
      'oozie-examples/input-data' directory. The examples will create output under the 
      'examples/output-data' directory in HDFS.



- Updating the Oozie Config Files

    # Move to the simple MapReduce example directory
    $ cd oozie-examples/apps/map-reduce/


    This directory contains 2 files and a 'lib' directory:

      1. The 'job.properties' file defines parameters (eg path names, ports) for a job.  This file
           may change per job.

      2. The 'workflow.xml' file provides the actual workflow for the job.  In this case, it is a
           simple MapReduce (pass/fail).  This file usually stays the same between jobs.


    The 'job.properties' file included with the examples requires a few edits to work properly.
      Let's change the following lines:


    # Change the host name of the NameNode and ResourceManager
    nameNode=hdfs://_HOSTNAME_:8020
    jobTracker=_HOSTNAME_:8050


    # Change the examplesRoot to reflect the changes made previously
    examplesRoot=oozie-examples


    These changes must be done for all the 'job.properties' files in the Oozie examples we choose
      to run.



- Running the Simple MapReduce Example

    Our 'workflow.xml' file has the following workflow nodes:

      <start to="mr-node"/>
      <action name="mr-node">
      <kill name="fail">
      <end name="end"/>


    # Run the Oozie MapReduce example job
    $ oozie job -run -oozie http://limulus:11000/oozie -config job.properties

    job: 0000001-150424174853048-oozie-oozi-W


    # To avoid having to provide the -oozie option with the Oozie URL every time we run the
    #   oozie command, we can set the OOZIE_URL environment variable
    $ $ export OOZIE_URL="http://limulus:11000/oozie"


    # Get status of a particular job
    $ oozie job -info 0000001-150424174853048-oozie-oozi-W



- Running the Oozie Demo Application

    The 'oozie-examples/apps/demo' directory contains a more sophisticated example.  This workflow
      contains MapReduce, Pig, and file system tasks, as well as fork, join, decision, action,
      start, stop, kill, and end nodes.

    # Move to the demo directory and run the workflow
    $ cd oozie-examples/apps/demo
    $ oozie job -run -config job/properties


    We can track the job using either the Oozie command line interface or the Oozie web console.

    To start the web console from within Ambari, click on the Oozie service, then click on the Quick
      Links pull-down, and select 'Oozie Web UI'.

    Alternatively, we can start the Oozie web UI by connecting to the Oozie server directly:
      http://localhost:11000/oozie/



- List of Oozie Job Commands

    # Run a workflow job
    $ oozie job -run -config JOB_PROPERTIES


    # Submit a workflow job
    $ oozie job -submit -config JOB_PROPERTIES


    # Start a submitted job
    $ oozie job -start _OOZIE_JOB_ID_


    # Check a job's status
    $ oozie job -info _OOZIE_JOB_ID_


    # Suspend a workflow
    $ oozie job -suspend _OOZIE_JOB_ID_


    # Resume a workflow
    $ oozie job -resume _OOZIE_JOB_ID_


    # Rerun a workflow
    $ oozie job -rerun _OOZIE_JOB_ID_ -config JOB_PROPERTIES


    # Kill a job
    $ oozie job -kill _OOZIE_JOB_ID_


    # View server logs
    $ oozie job  -logs _OOZIE_JOB_ID_
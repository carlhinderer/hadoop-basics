------------------------------------------------------------
CHAPTER 4 - RUNNING EXAMPLE PROGRAMS
------------------------------------------------------------

- Running MapReduce Examples

    - All Hadoop releases come with MapReduce example applications.  Often, they are under
        '/opt/', but sometimes they are in other directories.  

        # Maybe theyre in /opt
        $ ls /opt/hadoop-2.6.0/share/hadoop/mapreduce/


        # Find the mapreduce examples
        $ find / -name "hadoop-mapreduce-examples*.jar" -print


    - In our sample environment (HDP 2.2 with Hadoop 2.6), the location of the examples is
        '/usr/hdp/2.2.4.2-2/hadoop-mapreduce'.  For the purposes of this example, we'll define
        an environment variable to make it easier.

        # Define environment variable for mapreduce examples
        $ export HADOOP_EXAMPLES=/usr/hdp/2.2.4.2-2/hadoop-mapreduce


    - To list the available examples, we can use the following command.  For our example, we will
        run the 'pi' and 'terasort' examples.

        # List example mapreduce applications
        $ yarn jar $HADOOP_EXAMPLES/hadoop-mapreduce-examples.jar


    - To run the 'PI' example, we can use the following command.  

        # Run the pi example
        $ yarn jar $HADOOP_EXAMPLES/hadoop-mapreduce-examples.jar pi 16 1000000



- Using the Web GUI to Monitor Examples

    - We can use the YARN ResourceManager web GUI to monitor and find information about YARN jobs.
        A menu on the left provides navigation to the nodes table, various job categories, and the
        Capacity Scheduler.  


    - This interface can be opened directly from the Ambari YARN service 'Quick Links' menu or
        by navigating to http://hostname:8088.



- Running Basic Hadoop Benchmarks

    - Many Hadoop benchmarks can provide real insight into cluster performance.  The 2 benchmarks
        discussed in this section, 'terasort' and 'TestDFSIO', provide a good sense of how well your
        Hadoop installation is operating and can be compared with public data published for other
        Hadoop systems.



- Running the Terasort Test

    - The 'terasort' benchmark sorts a specified amount of randomly generated data.  This benchmark
        provides combined testing of the HDFS and MapReduce layers of a Hadoop cluster.  A full
        'terasort' benchmark run consists of the following 3 steps:

          1. Generating the input data via 'teragen' program

          2. Running the actual 'terasort' benchmark on the input data

          3. Validating the sorted output data via the 'terravalidate' program


    - The following series of commands will run the benchmark for 50GB of data as user 'hdfs'.
        Make sure the '/user/hdfs' directory exists in HDFS before running the benchmarks.

        # Run teragen to generate rows of random data to sort
        $ yarn jar $HADOOP_EXAMPLES/hadoop-mapreduce-examples.jar teragen 500000000 \
            /user/hdfs/TeraGen-50GB


        # Run terasort to sort the database
        $ yarn jar $HADOOP_EXAMPLES/hadoop-mapreduce-examples.jar terasort \
            /user/hdfs/TeraGen-50GB /user/hdfs/TeraSort-50GB


        # Run teravalidate to validate the sort
        $ yarn jar $HADOOP_EXAMPLES/hadoop-mapreduce-examples.jar teravalidate \
            /user/hdfs/TeraSort-50GB /user/hdfs/TeraValid-50GB


        # Delete the generated files
        $ hdfs dfs -rm -r -skipTrash Tera*



- Running the TestDFSIO Benchmark

    - Hadoop also includes an HDFS benchmark application called 'TestDFSIO', which is a read and
        write test for HDFS.  It will write or read a number of files to and from HDFS and is
        designed in such a way that is will use one map task per file.  The file size and number
        of files are specified as command-line arguments.


    - Running the 'TestDFSIO' benchmark consists of the following steps:

        # Run TestDFSIO in write mode and create data
        $ yarn jar $HADOOP_EXAMPLES/hadoop-mapreduce-client-jobclient-tests.jar TestDFSIO \
            -write  -nrFiles 16 -fileSize 1000


        # Run TestDFSIO in read mode
        $ yarn jar  $HADOOP_EXAMPLES/hadoop-mapreduce-client-jobclient-tests.jar TestDFSIO \
            -read  -nrFiles 16 -fileSize 1000


        # Clean up the TestDFSIO data
        $ yarn jar  $HADOOP_EXAMPLES/hadoop-mapreduce-client-jobclient-tests.jar TestDFSIO -clean



- Managing Hadoop MapReduce Jobs

    - Hadoop MapReduce jobs can be managed using the 'mapred job' command.  The most important
        options for this command are '-list', '-kill', and '-status'.  


        # Get all of the job-ids
        $ mapred job -list


        # Get the status of a job
        $ mapred job -status <job-id>


        # Kill a job
        $ mapred job -kill <job-id>
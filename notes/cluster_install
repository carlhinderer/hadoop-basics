
1. Create AWS EC2 instances

      - Step 1: Use the CentOS 7 image
      - Step 2: Use the t2.xlarge (4 CPUs, 16GB RAM) Instance Type
      - Step 3: Set 'Number of instances' to 3
      - Step 4: Choose 100GB Magnetic Storage
      - Step 5: Add a new tag with Key='Name' and Value='Hadoop Nodes'
      - Step 6: Create a new security group
                  - Type = 'Custom TCP'
                  - Port Range = '0-65535'
                  - Source = 'Anywhere'
                  - Description = 'hadoop-nodes'
      - Step 7: Click 'Launch' and the key pair dialog comes up
                  - Select 'Create a new key pair'
                  - Key Pair Name = 'hadoop-cluster'
                  - Click 'Download Key Pair'
                  - Then click launch

      - Modify the permissions of the key file downloaded on your machine
          chmod 400 hadoop-cluster.pem

      - Give a name to each of the servers we created
          hadoop-ambari-server
          hadoop-datanode-1
          hadoop-datanode-2


2. Configure EC2 Instances

      - Connect to each instance
          ssh -i hadoop-cluster.pem centos@13.56.251.229

      - Update packages on each machine
          sudo yum update

      - Make centos the superuser on each machine
          sudo visudo

          # Add this line after 'root ALL=(ALL) ALL'
          centos ALL=(ALL) ALL

          # Save the file

      - On each machine, verify the hostname
          hostname -f

      - Edit the network configuration file
          sudo vi /etc/sysconfig/network

          # Add these pairs
          NETWORKING=yes
          NOZEROCONF=yes
          HOSTNAME=<fqdn>

      - Configure IP tables to disable firewall daemon while we install services
          sudo systemctl disable firewalld
          sudo service firewalld stop

      - Install unzip and wget
          sudo yum install unzip
          sudo yum install wget

      - Disable SELinux
          # For current session
          sudo setenforce 0

          #  Permanent
          sudo vi /etc/selinux/config
          # Add this line
          SELINUX=disabled
          # Save the file

          # Reboot

          # Grand rwx permissions for new files and folders
          sudo vi /etc/profile
          # Add this line at end of file
          umask 0022

      - Install NTP
          sudo yum install -y ntp && 
            sudo systemctl start ntpd && 
            sudo systemctl enable ntpd

          # Start NPT at boot
          sudo systemctl disable chronyd.service



3. Install Prereq Components

      - Copy the private key we created earlier to the ambari server

          # Copy the key from our current machine to ambari server
          scp -i hadoop-cluster.pem hadoop-cluser.pem centos@13.56.251.229:

          # Verify that the key is there
          ls

          # Now, we should be able to log into the 2 datanode servers from
          #   the ambari server (using the private DNS address from the Amazon
          #   console rather than the public one)
          ssh -i hadoop-cluster.pem centos@ip-172-31-25-35.us-west-1.compute.internal
          ssh -i hadoop-cluster.pem centos@ip-172-31-17-22.us-west-1.compute.internal


      - Next, we install MySQL on datanode-2.  This is for 2 reasons:
          1. Ambari will store its configuration here
          2. Hive will keep its metadata here

          # Install mysql
          wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm
          sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm
          sudo yum update
          sudo yum install mysql-server

          # Start mysql server
          sudo systemctl start mysqld

          # Set security settings
          mysql_secure_installation
          # Set MySql pw = PW
          # Remove anonymous users - Yes
          # Disallow root login remotely - Yes
          # Remove test database and access to it - Yes
          # Reload privilege tables now - Yes


          # Add mysql pw to /tmp/password
          sudo vi tmp/password
          # Add this line
          mysql root password - PW


      - Create Database For Oozie

          mysql -u root -p
          CREATE USER 'oozie'@'%' IDENTIFIED BY 'oozie123';
          GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'%';
          FLUSH PRIVILEGES;
          CREATE DATABASE oozie;


      - Create Database For Hive

          mysql -u root -p
          CREATE USER hive@'%' IDENTIFIED BY 'hive123';
          GRANT ALL PRIVILEGES ON *.* TO 'hive'@'%';
          FLUSH PRIVILEGES;
          CREATE DATABASE hive;


      - Create Database For Ranger

          mysql -u root -p
          CREATE USER ranger@'%' IDENTIFIED BY 'ranger123';
          GRANT ALL PRIVILEGES ON *.* TO 'ranger'@'%';
          FLUSH PRIVILEGES;
          CREATE DATABASE ranger;


      - Create Database For rangerkms

          mysql -u root -p
          CREATE USER rangerkms@'%' IDENTIFIED BY 'rangerkms123';
          GRANT ALL PRIVILEGES ON *.* TO 'rangerkms'@'%';
          FLUSH PRIVILEGES;
          CREATE DATABASE rangerkms;


      - Download the mysql connector on the ambari server

          sudo yum install mysql-connector-java*

          # Check to make sure its there
          ls -lh /usr/share/java/mysql-connector-java.jar


      - Install java on the data nodes

          sudo yum install java-1.8.0-openjdk-devel


      - Set environment variables to point to javac

          export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.212.b04-0.el7_6.x86_64/jre
          export PATH=$JAVA_HOME/bin:$PATH


      - Install JCE on the data nodes

          # Download from Oracle onto local machine
          https://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html

          # scp it to the 2 data nodes
          scp -i Keys/hadoop-cluster.pem jce_policy-8.zip centos@13.57.198.253:
          scp -i Keys/hadoop-cluster.pem jce_policy-8.zip centos@54.183.121.66:

          # Unzip the file on the data nodes
          sudo unzip -o -j -q jce_policy-8.zip \
            -d /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.212.b04-0.el7_6.x86_64/jre/lib/security/


4. Install and Use Apache Ambari

      - Install ambari on the ambari server

          wget -nv http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.7.3.0/ambari.repo \ 
             -O /etc/yum.repos.d/ambari.repo

          sudo yum install ambari-server

          # Set up ambari-server
          sudo ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar
          sudo ambari-server setup

          # Start the ambari server
          sudo ambari-server start


      - Navigate to ambari in your browser

          13.56.251.229:8080

          # Default creds
          u: admin
          p: admin

          # Go to 'Users' and change the default admin pw


      - Use the cluster install wizard

          - Use public repositories

          - Install Options:

              # Target Hosts (use private DNS names)
              ip-172-31-17-141.us-west-1.compute.internal
              ip-172-31-25-35.us-west-1.compute.internal
              ip-172-31-17-22.us-west-1.compute.internal

              # Private Key
              Paste from file

              # SSH User Account
              centos

          - Assign Masters:

              Leave defaults chosen by Ambari, except
                - Put HiveServer on datanode-2
                - Put HiveMetastore on datanode-2
                - Put Oozie Server on datanode-2

          - Assign Slaves and Clients

              Make all machines DataNodes
              Make all machines NFSGateways
              Make all machines NodeManagers
              Make all machines RegionServers (used by HBase)
              Make all machines Supervisor
              Make all machines Flume
              Make all machines Client

              Make datanodes Livy Server
              Make datanodes Spark Thrift Server
              Make datanodes Livy For Spark2 Server
              Make datanodes Spark2 Thrift Server